{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd9c2b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, timeit\n",
    "from datetime import datetime\n",
    "import os, glob, sys\n",
    "import natsort, copy, random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5efe0b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_random_seed(seed, pytorch=True):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    try:\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available()==True:\n",
    "            torch.cuda.manual_seed(seed)\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "    except:\n",
    "        pass\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378dcf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread_kor ( filePath, mode=cv2.IMREAD_UNCHANGED ) : \n",
    "    stream = open( filePath.encode(\"utf-8\") , \"rb\") \n",
    "    bytes = bytearray(stream.read()) \n",
    "    numpyArray = np.asarray(bytes, dtype=np.uint8)\n",
    "    return cv2.imdecode(numpyArray , mode)\n",
    "def imwrite_kor(filename, img, params=None): \n",
    "    try: \n",
    "        ext = os.path.splitext(filename)[1] \n",
    "        result, n = cv2.imencode(ext, img, params) \n",
    "        if result:\n",
    "            with open(filename, mode='w+b') as f: \n",
    "                n.tofile(f) \n",
    "                return True\n",
    "        else: \n",
    "            return False \n",
    "    except Exception as e: \n",
    "        print(e) \n",
    "        return False\n",
    "def str_to_class(classname):\n",
    "    return getattr(sys.modules[__name__], classname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cdbde59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagesDataset(Dataset):\n",
    "    def __init__(self, image_path_list, target_path_list, transform=None):\n",
    "        self.image_path_list = image_path_list\n",
    "        self.target_path_list = target_path_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_path_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_path_list[idx]\n",
    "        mask_path = self.target_path_list[idx]\n",
    "        image = np.load(image_path) \n",
    "        mask = imread_kor(mask_path)\n",
    "        if image.shape[0]!=512:\n",
    "            print(image.shape, mask.shape, image_path, mask_path)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "        mask[mask > 0] = 1\n",
    "        return image, mask, image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "941f8ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, lr):\n",
    "    lr = lr * (0.5 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a66c90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tversky_index(yhat, ytrue, alpha=0.3, beta=0.7, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Computes Tversky index\n",
    "    Args:\n",
    "        yhat (Tensor): predicted masks\n",
    "        ytrue (Tensor): targets masks\n",
    "        alpha (Float): weight for False positive\n",
    "        beta (Float): weight for False negative\n",
    "                    `` alpha and beta control the magnitude of penalties and should sum to 1``\n",
    "        epsilon (Float): smoothing value to avoid division by 0\n",
    "    output:\n",
    "        tversky index value\n",
    "    \"\"\"\n",
    "    TP = torch.sum(yhat * ytrue, (1,2,3))\n",
    "    FP = torch.sum((1. - ytrue) * yhat, (1,2,3))\n",
    "    FN = torch.sum((1. - yhat) * ytrue, (1,2,3))\n",
    "    \n",
    "    return TP/(TP + alpha * FP + beta * FN + epsilon)\n",
    "\n",
    "\n",
    "def tversky_focal_loss(yhat, ytrue, alpha=0.7, beta=0.3, gamma=0.75):\n",
    "    \"\"\"\n",
    "    Computes tversky focal loss for highly umbalanced data\n",
    "    https://arxiv.org/pdf/1810.07842.pdf\n",
    "    Args:\n",
    "        yhat (Tensor): predicted masks\n",
    "        ytrue (Tensor): targets masks\n",
    "        alpha (Float): weight for False positive\n",
    "        beta (Float): weight for False negative\n",
    "                    `` alpha and beta control the magnitude of penalties and should sum to 1``\n",
    "        gamma (Float): focal parameter\n",
    "                    ``control the balance between easy background and hard ROI training examples``\n",
    "    output:\n",
    "        tversky focal loss value with `mean` reduction\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.mean(torch.pow(1 - tversky_index(yhat, ytrue, alpha, beta), gamma))\n",
    "\n",
    "def focal_loss(yhat, ytrue, alpha=0.75, gamma=2):\n",
    "    \"\"\"\n",
    "    Computes Î±-balanced focal loss from FAIR\n",
    "    https://arxiv.org/pdf/1708.02002v2.pdf\n",
    "    Args:\n",
    "        yhat (Tensor): predicted masks\n",
    "        ytrue (Tensor): targets masks\n",
    "        alpha (Float): weight to balance Cross entropy value\n",
    "        gamma (Float): focal parameter\n",
    "    output:\n",
    "        loss value with `mean` reduction\n",
    "    \"\"\"\n",
    "\n",
    "    # compute the actual focal loss\n",
    "    focal = -alpha * torch.pow(1. - yhat, gamma) * torch.log(yhat)\n",
    "    f_loss = torch.sum(ytrue * focal, dim=1)\n",
    "\n",
    "    return torch.mean(f_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6ee6e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Intersection_over_Union(yhat, ytrue, threshold=0.5, epsilon=1e-6, nan_process = 'remove'):\n",
    "    \"\"\"\n",
    "    Computes Intersection over Union metric\n",
    "    Args:\n",
    "        yhat (Tensor): predicted masks (batch_size, 1, height, width)\n",
    "        ytrue (Tensor): targets masks (batch_size, 1, height, width)\n",
    "        threshold (Float): threshold for pixel classification\n",
    "        epsilon (Float): smoothing parameter for numerical stability\n",
    "    output:\n",
    "        iou value with `mean` reduction\n",
    "    \"\"\"\n",
    "    intersection = ((yhat>threshold).long() & ytrue.long()).float().sum((1,2,3))\n",
    "    union = ((yhat>threshold).long() | ytrue.long()).float().sum((1,2,3))\n",
    "    if nan_process == 'remove': # if sum of true == 0, remove\n",
    "        sum_bool = torch.sum(torch.flatten(ytrue,1),1).bool()\n",
    "        iou =(intersection/(union))#.reshape(intersection.shape[0],-1)\n",
    "        iou = torch.nanmean(iou,dim=0)\n",
    "        if torch.isnan(iou):\n",
    "            return 0\n",
    "        return (torch.mean(iou)).item()\n",
    "\n",
    "def Dice_Coefficient(yhat, ytrue, epsilon=1e-6, nan_process = 'remove'):\n",
    "    \"\"\"\n",
    "    Computes a soft Dice Loss\n",
    "    Args:\n",
    "        yhat (Tensor): predicted masks (batch_size, 1, height, width)\n",
    "        ytrue (Tensor): targets masks (batch_size, 1, height, width)\n",
    "        epsilon (Float): smoothing value to avoid division by 0\n",
    "    output:\n",
    "        DL value with `mean` reduction\n",
    "    \"\"\"\n",
    "    # compute Dice components\n",
    "    intersection = torch.sum(yhat * ytrue, (1,2,3))\n",
    "    cardinal = torch.sum(yhat + ytrue, (1,2,3))\n",
    "    if nan_process == 'remove': # if sum of true == 0, remove\n",
    "        sum_bool = torch.sum(torch.flatten(ytrue,1),1).bool()\n",
    "        dice = (2 * intersection / (cardinal))#.reshape(intersection.shape[0],-1)\n",
    "        dice = torch.nanmean(dice,dim=0)\n",
    "        if torch.isnan(dice):\n",
    "            return 0\n",
    "        return (torch.mean(dice)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec576ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, epoch, \\\n",
    "          model, criterion, optimizer, device\n",
    "          ):\n",
    "    model.train()\n",
    "    limit=0\n",
    "    train_losses=AverageMeter()\n",
    "    for i, (input, target, _) in enumerate(train_loader):\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "        output = nn.Sigmoid()(model(input))\n",
    "        loss = criterion(output,target).float()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        train_losses.update(loss.detach().cpu().numpy(),input.shape[0])\n",
    "    Train_Loss=np.round(train_losses.avg,6)\n",
    "    return Train_Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a48bd9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(validation_loader, \n",
    "          model, criterion, device,\n",
    "        model_path=False,\n",
    "             return_image_paths=False,\n",
    "          ):\n",
    "    if model_path!=False:\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    for i, (input, target, image_path) in enumerate(validation_loader):\n",
    "        input =input.to(device)\n",
    "        target = target.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = nn.Sigmoid()(model(input))\n",
    "        if i==0:\n",
    "            targets=target\n",
    "            outputs=output\n",
    "            if return_image_paths==True:\n",
    "                image_paths = image_path\n",
    "        else:\n",
    "            targets=torch.cat((targets,target))\n",
    "            outputs=torch.cat((outputs,output),axis=0)\n",
    "            if return_image_paths==True:\n",
    "                image_paths += image_path\n",
    "    if return_image_paths==True:\n",
    "        return outputs, targets, image_paths\n",
    "    return outputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6aa25ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0046d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Do_Experiment(iteration, model_name, model, Optimizer, lr,  number_of_classes, epochs, Metrics,df,device):\n",
    "    train_dataset = ImagesDataset(train_image_path_list, train_target_path_list, transform)\n",
    "    validation_dataset = ImagesDataset(validation_image_path_list, validation_target_path_list, transform)\n",
    "    test_dataset = ImagesDataset(test_image_path_list, test_target_path_list, transform)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size,\n",
    "    num_workers=num_workers, pin_memory=pin_memory\n",
    "    )\n",
    "    validation_loader = torch.utils.data.DataLoader(\n",
    "        validation_dataset, batch_size=batch_size, \n",
    "        num_workers=num_workers, pin_memory=pin_memory\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=batch_size, \n",
    "        num_workers=num_workers, pin_memory=pin_memory\n",
    "    )\n",
    "    start = timeit.default_timer()\n",
    "    train_bool=True\n",
    "    test_bool=True\n",
    "    if loss_function == 'Tversky Focal Loss':\n",
    "        criterion=tversky_focal_loss\n",
    "    else:\n",
    "        criterion=torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    if Optimizer=='Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    elif Optimizer == 'SGD':\n",
    "        momentum = 0.9\n",
    "        weight_decay = 1e-4\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum ,weight_decay=weight_decay)\n",
    "    elif Optimizer =='AdamW':\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    save_dir='saved_model'\n",
    "    try:\n",
    "        os.mkdir(save_dir)\n",
    "    except:\n",
    "        pass\n",
    "    if train_bool:\n",
    "        now = datetime.now()\n",
    "        Train_date=now.strftime(\"%y%m%d_%H%M%S\")\n",
    "        print('Training Start Time:',Train_date)\n",
    "        best=9999\n",
    "        best_epoch=1\n",
    "        Early_Stop=0\n",
    "        Early_Stop_Start=30\n",
    "        train_start_time = timeit.default_timer()\n",
    "        Train_Losses=[]\n",
    "        Validation_Losses=[]\n",
    "        for epoch in range(1, epochs+1):\n",
    "            adjust_learning_rate(optimizer, epoch, lr)\n",
    "            Train_Loss = train(train_loader, epoch, \n",
    "              model, criterion, optimizer, device\n",
    "              )\n",
    "            outputs, targets  \\\n",
    "            = validate(validation_loader, \n",
    "              model, criterion, device\n",
    "              )\n",
    "            Loss = np.round(criterion(outputs,targets).cpu().numpy(),6)            \n",
    "            iou = np.round(Intersection_over_Union(outputs, targets),3)\n",
    "            dice = np.round(Dice_Coefficient(outputs, targets),3)\n",
    "            now = datetime.now()\n",
    "            date=now.strftime(\"%y%m%d_%H%M%S\")\n",
    "            print(str(epoch)+'EP('+date+'):',end=' ')\n",
    "            print('T_Loss: ' + str(Train_Loss), end=' ')\n",
    "            print('V_Loss: ' + str(Loss), end=' ')\n",
    "            print('IoU: ' + str(iou), end=' ')\n",
    "            print('Dice: ' + str(dice), end='\\n')\n",
    "                        \n",
    "            if Loss<best:\n",
    "                torch.save(model.state_dict(), save_dir+'/'+model_name+'_'+Dataset_name+'.pt')\n",
    "                best_epoch = epoch\n",
    "                best = Loss\n",
    "                print('Best Epoch:',best_epoch,'Loss:',Loss)\n",
    "        train_stop_time = timeit.default_timer()\n",
    "    if test_bool:\n",
    "        now = datetime.now()\n",
    "        date=now.strftime(\"%y%m%d_%H%M%S\")\n",
    "        print('Test Start Time:',date)\n",
    "        outputs, targets, image_paths \\\n",
    "            = validate(test_loader, \n",
    "              model, criterion, device,\n",
    "            model_path=save_dir+'/'+model_name+'_'+Dataset_name+'.pt',\n",
    "                       return_image_paths=True\n",
    "              )        \n",
    "        Loss = np.round(criterion(outputs,targets).cpu().numpy(),6)\n",
    "        iou = np.round(Intersection_over_Union(outputs, targets),3)\n",
    "        dice = np.round(Dice_Coefficient(outputs, targets),3)\n",
    "\n",
    "        now = datetime.now()\n",
    "        date=now.strftime(\"%y%m%d_%H%M%S\")\n",
    "        print('Best Epoch:',best_epoch)\n",
    "        print('Test('+date+'): '+'Loss: ' + str(Loss),end=' ')\n",
    "        print('IoU: ' + str(iou), end=' ')\n",
    "        print('Dice: ' + str(dice), end='\\n')                    \n",
    "                            \n",
    "        stop = timeit.default_timer()\n",
    "        m, s = divmod((train_stop_time - train_start_time)/epoch, 60)\n",
    "        h, m = divmod(m, 60)\n",
    "        Time_per_Epoch = \"%02d:%02d:%02d\" % (h, m, s)\n",
    "\n",
    "        m, s = divmod(stop - start, 60)\n",
    "        h, m = divmod(m, 60)\n",
    "        Time = \"%02d:%02d:%02d\" % (h, m, s)\n",
    "        print(Time)\n",
    "        \n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        total_params = format(total_params , ',')\n",
    "        Performances = [iteration, Dataset_name, model_name, loss_function, lr, batch_size, epochs,   Loss, iou, dice, total_params,Time, best_epoch, Time_per_Epoch]\n",
    "        df = df.append(pd.Series(Performances, index=df.columns), ignore_index=True)\n",
    "    now = datetime.now()\n",
    "    date=now.strftime(\"%y%m%d_%H%M%S\")\n",
    "    print('End',date)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5242cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íê²½ë³ì ì¤ì \n",
    "sys.path.append(\"..\")\n",
    "module_names=['OTSNet']\n",
    "for module_name in module_names:\n",
    "    exec('from models.'+module_name+' import *')\n",
    "model_names= ['OTSNet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0afb433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.7\n",
    "in_channels = 3\n",
    "\n",
    "number_of_classes = 1\n",
    "loss_function = 'Tversky Focal Loss'\n",
    "Optimizers = ['Adam']\n",
    "LRs = [1e-4]\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "iterations = [1,10]\n",
    "devices = [0,1] \n",
    "Target_Datasets = ['reflex_mask']\n",
    "Dataset_dir = 'Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13456187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Start Time: 230923_175610\n",
      "['Dataset/Masks/reflex_mask']\n",
      "['Dataset/Originals/reflex_ori']\n",
      "Batch Size: 32\n",
      "Train Size 0.7\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "Experiment_date=now.strftime(\"%y%m%d_%H%M%S\")\n",
    "print('Experiment Start Time:',Experiment_date)\n",
    "\n",
    "Metrics=['Iteration','Dataset','Model Name', 'Loss Function', 'LR', 'Batch size', '#Epochs',  'Loss', 'mIoU', 'mDice','Total Params','Train-Predction Time','Best Epoch','Time per Epoch']\n",
    "image_paths_dirs=[]\n",
    "target_dirs = [path  for path in natsort.natsorted(glob.glob(Dataset_dir+'/Masks/*'))]\n",
    "print(target_dirs)\n",
    "for target_dir in target_dirs:\n",
    "    image_paths_dirs.append(Dataset_dir+'/Originals/'+os.path.basename(target_dir).split('_')[0]+'_ori')\n",
    "print(image_paths_dirs)  \n",
    "df = pd.DataFrame(index=None, columns=Metrics)\n",
    "csv_file = False \n",
    "try:\n",
    "    if csv_file != False:\n",
    "        csv_file_for_modifying = 'Segmentation_Model_Comparison_Performance_220511_045617.csv'\n",
    "        df= pd.read_csv(csv_file_for_modifying, encoding='cp949')\n",
    "        df.to_csv('Segmentation_Model_Comparison_Performance_'+Experiment_date+'.csv', index=False, header=True, encoding=\"cp949\")\n",
    "except:\n",
    "    df = pd.DataFrame(index=None, columns=Metrics)\n",
    "print('Batch Size:',batch_size)\n",
    "print('Train Size',train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "265c105f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 reflex_mask\n",
      "OTSNet\n",
      "LR: 0.0001\n",
      "Training Start Time: 230923_175629\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/userHome/userhome3/taekyung/miniconda3/envs/ots/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/userHome/userhome3/taekyung/miniconda3/envs/ots/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/userHome/userhome3/taekyung/MYNet/models/OTSNet.py\", line 106, in forward\n    x21 = F.relu(self.bn21(self.conv21(x1p)))\n  File \"/userHome/userhome3/taekyung/miniconda3/envs/ots/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/userHome/userhome3/taekyung/miniconda3/envs/ots/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 446, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/userHome/userhome3/taekyung/miniconda3/envs/ots/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 442, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\nRuntimeError: Given groups=1, weight of size [64, 32, 3, 3], expected input[16, 64, 256, 256] to have 32 channels, but got 64 channels instead\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 62\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mDo_Experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mnumber_of_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSegmentation_Model_Comparison_Performance_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mExperiment_date\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcp949\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 52\u001b[0m, in \u001b[0;36mDo_Experiment\u001b[0;34m(iteration, model_name, model, Optimizer, lr, number_of_classes, epochs, Metrics, df, device)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     51\u001b[0m     adjust_learning_rate(optimizer, epoch, lr)\n\u001b[0;32m---> 52\u001b[0m     Train_Loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     outputs, targets  \\\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;241m=\u001b[39m validate(validation_loader, \n\u001b[1;32m     57\u001b[0m       model, criterion, device\n\u001b[1;32m     58\u001b[0m       )\n\u001b[1;32m     59\u001b[0m     Loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(criterion(outputs,targets)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(),\u001b[38;5;241m6\u001b[39m)            \n",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, epoch, model, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 10\u001b[0m output \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSigmoid()(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output,target)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/ots/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ots/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:168\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    167\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 168\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/ots/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:178\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ots/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py:86\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     84\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m---> 86\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/ots/lib/python3.8/site-packages/torch/_utils.py:434\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 434\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/userHome/userhome3/taekyung/miniconda3/envs/ots/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/userHome/userhome3/taekyung/miniconda3/envs/ots/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/userHome/userhome3/taekyung/MYNet/models/OTSNet.py\", line 106, in forward\n    x21 = F.relu(self.bn21(self.conv21(x1p)))\n  File \"/userHome/userhome3/taekyung/miniconda3/envs/ots/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/userHome/userhome3/taekyung/miniconda3/envs/ots/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 446, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/userHome/userhome3/taekyung/miniconda3/envs/ots/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 442, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\nRuntimeError: Given groups=1, weight of size [64, 32, 3, 3], expected input[16, 64, 256, 256] to have 32 channels, but got 64 channels instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32EP(230909_174554): T_Loss: 0.211523 V_Loss: 0.25161 IoU: 0.713 Dice: 0.813\n",
      "Best Epoch: 32 Loss: 0.25161\n",
      "33EP(230909_174606): T_Loss: 0.211883 V_Loss: 0.251046 IoU: 0.734 Dice: 0.827\n",
      "Best Epoch: 33 Loss: 0.251046\n",
      "34EP(230909_174618): T_Loss: 0.208511 V_Loss: 0.250836 IoU: 0.731 Dice: 0.824\n",
      "Best Epoch: 34 Loss: 0.250836\n",
      "35EP(230909_174630): T_Loss: 0.210603 V_Loss: 0.248454 IoU: 0.732 Dice: 0.825\n",
      "Best Epoch: 35 Loss: 0.248454\n",
      "36EP(230909_174643): T_Loss: 0.201464 V_Loss: 0.249992 IoU: 0.709 Dice: 0.81\n",
      "37EP(230909_174654): T_Loss: 0.19602 V_Loss: 0.249826 IoU: 0.732 Dice: 0.825\n",
      "38EP(230909_174707): T_Loss: 0.191331 V_Loss: 0.250025 IoU: 0.701 Dice: 0.807\n",
      "39EP(230909_174718): T_Loss: 0.191513 V_Loss: 0.256932 IoU: 0.727 Dice: 0.821\n",
      "40EP(230909_174730): T_Loss: 0.202553 V_Loss: 0.253601 IoU: 0.719 Dice: 0.818\n",
      "41EP(230909_174742): T_Loss: 0.204592 V_Loss: 0.317054 IoU: 0.584 Dice: 0.712\n",
      "42EP(230909_174753): T_Loss: 0.209066 V_Loss: 0.257322 IoU: 0.697 Dice: 0.799\n",
      "43EP(230909_174806): T_Loss: 0.194453 V_Loss: 0.254181 IoU: 0.702 Dice: 0.805\n",
      "44EP(230909_174818): T_Loss: 0.185781 V_Loss: 0.245051 IoU: 0.715 Dice: 0.815\n",
      "Best Epoch: 44 Loss: 0.245051\n",
      "45EP(230909_174829): T_Loss: 0.18013 V_Loss: 0.24517 IoU: 0.718 Dice: 0.818\n",
      "46EP(230909_174841): T_Loss: 0.174768 V_Loss: 0.241579 IoU: 0.737 Dice: 0.831\n",
      "Best Epoch: 46 Loss: 0.241579\n",
      "47EP(230909_174853): T_Loss: 0.170727 V_Loss: 0.247322 IoU: 0.706 Dice: 0.81\n",
      "48EP(230909_174905): T_Loss: 0.166173 V_Loss: 0.248714 IoU: 0.699 Dice: 0.806\n",
      "49EP(230909_174917): T_Loss: 0.164035 V_Loss: 0.25226 IoU: 0.73 Dice: 0.826\n",
      "50EP(230909_174928): T_Loss: 0.165106 V_Loss: 0.249696 IoU: 0.703 Dice: 0.807\n",
      "Test Start Time: 230909_174928\n",
      "Best Epoch: 46\n",
      "Test(230909_174930): Loss: 0.252314 IoU: 0.721 Dice: 0.819\n",
      "00:09:58\n",
      "End 230909_174930\n",
      "OTSNet\n",
      "LR: 0.0001\n",
      "Training Start Time: 230909_174930\n",
      "1EP(230909_174941): T_Loss: 0.999841 V_Loss: 0.999917 IoU: 0.002 Dice: 0.0\n",
      "Best Epoch: 1 Loss: 0.999917\n",
      "2EP(230909_174953): T_Loss: 0.999778 V_Loss: 0.99981 IoU: 0.008 Dice: 0.0\n",
      "Best Epoch: 2 Loss: 0.99981\n",
      "3EP(230909_175005): T_Loss: 0.999719 V_Loss: 0.999677 IoU: 0.01 Dice: 0.001\n",
      "Best Epoch: 3 Loss: 0.999677\n",
      "4EP(230909_175017): T_Loss: 0.999631 V_Loss: 0.999565 IoU: 0.03 Dice: 0.001\n",
      "Best Epoch: 4 Loss: 0.999565\n",
      "5EP(230909_175028): T_Loss: 0.999489 V_Loss: 0.999422 IoU: 0.071 Dice: 0.001\n",
      "Best Epoch: 5 Loss: 0.999422\n",
      "6EP(230909_175040): T_Loss: 0.999238 V_Loss: 0.999072 IoU: 0.174 Dice: 0.002\n",
      "Best Epoch: 6 Loss: 0.999072\n",
      "7EP(230909_175053): T_Loss: 0.998715 V_Loss: 0.998359 IoU: 0.186 Dice: 0.003\n",
      "Best Epoch: 7 Loss: 0.998359\n",
      "8EP(230909_175104): T_Loss: 0.997564 V_Loss: 0.997009 IoU: 0.363 Dice: 0.006\n",
      "Best Epoch: 8 Loss: 0.997009\n",
      "9EP(230909_175117): T_Loss: 0.99486 V_Loss: 0.994524 IoU: 0.28 Dice: 0.01\n",
      "Best Epoch: 9 Loss: 0.994524\n",
      "10EP(230909_175128): T_Loss: 0.982961 V_Loss: 0.979515 IoU: 0.265 Dice: 0.037\n",
      "Best Epoch: 10 Loss: 0.979515\n",
      "11EP(230909_175140): T_Loss: 0.940758 V_Loss: 0.999766 IoU: 0.001 Dice: 0.0\n",
      "12EP(230909_175151): T_Loss: 0.877543 V_Loss: 0.860129 IoU: 0.219 Dice: 0.187\n",
      "Best Epoch: 12 Loss: 0.860129\n",
      "13EP(230909_175203): T_Loss: 0.821671 V_Loss: 0.95336 IoU: 0.071 Dice: 0.059\n",
      "14EP(230909_175214): T_Loss: 0.78512 V_Loss: 0.649999 IoU: 0.399 Dice: 0.425\n",
      "Best Epoch: 14 Loss: 0.649999\n",
      "15EP(230909_175226): T_Loss: 0.726722 V_Loss: 0.681424 IoU: 0.352 Dice: 0.381\n",
      "16EP(230909_175237): T_Loss: 0.689271 V_Loss: 0.792122 IoU: 0.264 Dice: 0.256\n",
      "17EP(230909_175249): T_Loss: 0.634388 V_Loss: 0.50813 IoU: 0.542 Dice: 0.586\n",
      "Best Epoch: 17 Loss: 0.50813\n",
      "18EP(230909_175301): T_Loss: 0.585959 V_Loss: 0.546804 IoU: 0.521 Dice: 0.549\n",
      "19EP(230909_175312): T_Loss: 0.520193 V_Loss: 0.455153 IoU: 0.607 Dice: 0.64\n",
      "Best Epoch: 19 Loss: 0.455153\n",
      "20EP(230909_175324): T_Loss: 0.482566 V_Loss: 0.464344 IoU: 0.564 Dice: 0.617\n",
      "21EP(230909_175337): T_Loss: 0.400427 V_Loss: 0.344263 IoU: 0.702 Dice: 0.771\n",
      "Best Epoch: 21 Loss: 0.344263\n",
      "22EP(230909_175349): T_Loss: 0.322655 V_Loss: 0.318851 IoU: 0.695 Dice: 0.771\n",
      "Best Epoch: 22 Loss: 0.318851\n",
      "23EP(230909_175401): T_Loss: 0.297239 V_Loss: 0.298968 IoU: 0.69 Dice: 0.781\n",
      "Best Epoch: 23 Loss: 0.298968\n",
      "24EP(230909_175413): T_Loss: 0.288104 V_Loss: 0.29423 IoU: 0.664 Dice: 0.772\n",
      "Best Epoch: 24 Loss: 0.29423\n",
      "25EP(230909_175424): T_Loss: 0.280386 V_Loss: 0.281658 IoU: 0.676 Dice: 0.781\n",
      "Best Epoch: 25 Loss: 0.281658\n",
      "26EP(230909_175437): T_Loss: 0.263487 V_Loss: 0.276562 IoU: 0.686 Dice: 0.791\n",
      "Best Epoch: 26 Loss: 0.276562\n",
      "27EP(230909_175449): T_Loss: 0.25167 V_Loss: 0.27255 IoU: 0.693 Dice: 0.796\n",
      "Best Epoch: 27 Loss: 0.27255\n",
      "28EP(230909_175501): T_Loss: 0.247286 V_Loss: 0.276638 IoU: 0.674 Dice: 0.783\n",
      "29EP(230909_175513): T_Loss: 0.238805 V_Loss: 0.28271 IoU: 0.66 Dice: 0.772\n",
      "30EP(230909_175524): T_Loss: 0.233927 V_Loss: 0.263454 IoU: 0.701 Dice: 0.802\n",
      "Best Epoch: 30 Loss: 0.263454\n",
      "31EP(230909_175535): T_Loss: 0.227537 V_Loss: 0.268899 IoU: 0.682 Dice: 0.789\n",
      "32EP(230909_175547): T_Loss: 0.221732 V_Loss: 0.271236 IoU: 0.672 Dice: 0.783\n",
      "33EP(230909_175559): T_Loss: 0.216789 V_Loss: 0.264221 IoU: 0.69 Dice: 0.798\n",
      "34EP(230909_175611): T_Loss: 0.216624 V_Loss: 0.262499 IoU: 0.692 Dice: 0.799\n",
      "Best Epoch: 34 Loss: 0.262499\n",
      "35EP(230909_175622): T_Loss: 0.209183 V_Loss: 0.270319 IoU: 0.677 Dice: 0.788\n",
      "36EP(230909_175634): T_Loss: 0.205297 V_Loss: 0.264736 IoU: 0.689 Dice: 0.796\n",
      "37EP(230909_175647): T_Loss: 0.200908 V_Loss: 0.25663 IoU: 0.702 Dice: 0.805\n",
      "Best Epoch: 37 Loss: 0.25663\n",
      "38EP(230909_175658): T_Loss: 0.203563 V_Loss: 0.263443 IoU: 0.689 Dice: 0.797\n",
      "39EP(230909_175710): T_Loss: 0.197937 V_Loss: 0.259453 IoU: 0.699 Dice: 0.807\n",
      "40EP(230909_175722): T_Loss: 0.195385 V_Loss: 0.257253 IoU: 0.696 Dice: 0.803\n",
      "41EP(230909_175734): T_Loss: 0.193492 V_Loss: 0.263163 IoU: 0.68 Dice: 0.793\n",
      "42EP(230909_175746): T_Loss: 0.196569 V_Loss: 0.260929 IoU: 0.69 Dice: 0.796\n",
      "43EP(230909_175758): T_Loss: 0.192054 V_Loss: 0.263704 IoU: 0.688 Dice: 0.799\n",
      "44EP(230909_175809): T_Loss: 0.185416 V_Loss: 0.257678 IoU: 0.691 Dice: 0.802\n",
      "45EP(230909_175821): T_Loss: 0.181415 V_Loss: 0.255209 IoU: 0.699 Dice: 0.804\n",
      "Best Epoch: 45 Loss: 0.255209\n",
      "46EP(230909_175833): T_Loss: 0.186184 V_Loss: 0.259637 IoU: 0.689 Dice: 0.8\n",
      "47EP(230909_175844): T_Loss: 0.182637 V_Loss: 0.251641 IoU: 0.708 Dice: 0.812\n",
      "Best Epoch: 47 Loss: 0.251641\n",
      "48EP(230909_175856): T_Loss: 0.174504 V_Loss: 0.253244 IoU: 0.698 Dice: 0.806\n",
      "49EP(230909_175907): T_Loss: 0.169418 V_Loss: 0.260225 IoU: 0.692 Dice: 0.801\n",
      "50EP(230909_175919): T_Loss: 0.182842 V_Loss: 0.26478 IoU: 0.671 Dice: 0.787\n",
      "Test Start Time: 230909_175919\n",
      "Best Epoch: 47\n",
      "Test(230909_175921): Loss: 0.241719 IoU: 0.714 Dice: 0.817\n",
      "00:09:50\n",
      "End 230909_175921\n",
      "OTSNet\n",
      "LR: 0.0001\n",
      "Training Start Time: 230909_175921\n",
      "1EP(230909_175932): T_Loss: 0.999864 V_Loss: 0.999913 IoU: 0.0 Dice: 0.0\n",
      "Best Epoch: 1 Loss: 0.999913\n",
      "2EP(230909_175943): T_Loss: 0.999831 V_Loss: 0.999833 IoU: 0.002 Dice: 0.0\n",
      "Best Epoch: 2 Loss: 0.999833\n",
      "3EP(230909_175956): T_Loss: 0.999796 V_Loss: 0.999756 IoU: 0.003 Dice: 0.0\n",
      "Best Epoch: 3 Loss: 0.999756\n",
      "4EP(230909_180007): T_Loss: 0.999744 V_Loss: 0.999697 IoU: 0.004 Dice: 0.001\n",
      "Best Epoch: 4 Loss: 0.999697\n",
      "5EP(230909_180020): T_Loss: 0.999667 V_Loss: 0.999578 IoU: 0.014 Dice: 0.001\n",
      "Best Epoch: 5 Loss: 0.999578\n",
      "6EP(230909_180031): T_Loss: 0.999527 V_Loss: 0.99937 IoU: 0.19 Dice: 0.001\n",
      "Best Epoch: 6 Loss: 0.99937\n",
      "7EP(230909_180043): T_Loss: 0.999239 V_Loss: 0.998946 IoU: 0.17 Dice: 0.002\n",
      "Best Epoch: 7 Loss: 0.998946\n",
      "8EP(230909_180055): T_Loss: 0.998613 V_Loss: 0.998047 IoU: 0.246 Dice: 0.004\n",
      "Best Epoch: 8 Loss: 0.998047\n",
      "9EP(230909_180108): T_Loss: 0.997102 V_Loss: 0.995819 IoU: 0.227 Dice: 0.008\n",
      "Best Epoch: 9 Loss: 0.995819\n",
      "10EP(230909_180120): T_Loss: 0.99316 V_Loss: 0.995539 IoU: 0.379 Dice: 0.008\n",
      "Best Epoch: 10 Loss: 0.995539\n",
      "11EP(230909_180132): T_Loss: 0.968009 V_Loss: 0.970155 IoU: 0.227 Dice: 0.05\n",
      "Best Epoch: 11 Loss: 0.970155\n",
      "12EP(230909_180144): T_Loss: 0.896285 V_Loss: 0.999846 IoU: 0.0 Dice: 0.0\n",
      "13EP(230909_180155): T_Loss: 0.902842 V_Loss: 0.884583 IoU: 0.137 Dice: 0.137\n",
      "Best Epoch: 13 Loss: 0.884583\n",
      "14EP(230909_180207): T_Loss: 0.841085 V_Loss: 0.881232 IoU: 0.178 Dice: 0.148\n",
      "Best Epoch: 14 Loss: 0.881232\n",
      "15EP(230909_180219): T_Loss: 0.824334 V_Loss: 0.833523 IoU: 0.218 Dice: 0.193\n",
      "Best Epoch: 15 Loss: 0.833523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16EP(230909_180231): T_Loss: 0.756133 V_Loss: 0.669698 IoU: 0.389 Dice: 0.4\n",
      "Best Epoch: 16 Loss: 0.669698\n",
      "17EP(230909_180243): T_Loss: 0.67636 V_Loss: 0.613137 IoU: 0.416 Dice: 0.455\n",
      "Best Epoch: 17 Loss: 0.613137\n",
      "18EP(230909_180255): T_Loss: 0.625749 V_Loss: 0.619614 IoU: 0.392 Dice: 0.441\n",
      "19EP(230909_180307): T_Loss: 0.602521 V_Loss: 0.999767 IoU: 0.0 Dice: 0.0\n",
      "20EP(230909_180319): T_Loss: 0.583234 V_Loss: 0.542688 IoU: 0.439 Dice: 0.503\n",
      "Best Epoch: 20 Loss: 0.542688\n",
      "21EP(230909_180330): T_Loss: 0.587777 V_Loss: 0.554449 IoU: 0.447 Dice: 0.502\n",
      "22EP(230909_180341): T_Loss: 0.573546 V_Loss: 0.798608 IoU: 0.232 Dice: 0.238\n",
      "23EP(230909_180353): T_Loss: 0.595207 V_Loss: 0.54529 IoU: 0.534 Dice: 0.525\n",
      "24EP(230909_180404): T_Loss: 0.581781 V_Loss: 0.563654 IoU: 0.422 Dice: 0.487\n",
      "25EP(230909_180415): T_Loss: 0.56541 V_Loss: 0.541355 IoU: 0.472 Dice: 0.51\n",
      "Best Epoch: 25 Loss: 0.541355\n",
      "26EP(230909_180427): T_Loss: 0.554359 V_Loss: 0.526235 IoU: 0.472 Dice: 0.517\n",
      "Best Epoch: 26 Loss: 0.526235\n",
      "27EP(230909_180438): T_Loss: 0.550745 V_Loss: 0.601831 IoU: 0.456 Dice: 0.473\n",
      "28EP(230909_180450): T_Loss: 0.568268 V_Loss: 0.550492 IoU: 0.442 Dice: 0.502\n",
      "29EP(230909_180501): T_Loss: 0.547379 V_Loss: 0.515855 IoU: 0.476 Dice: 0.532\n",
      "Best Epoch: 29 Loss: 0.515855\n",
      "30EP(230909_180513): T_Loss: 0.535997 V_Loss: 0.516334 IoU: 0.468 Dice: 0.535\n",
      "31EP(230909_180525): T_Loss: 0.53155 V_Loss: 0.517548 IoU: 0.467 Dice: 0.532\n",
      "32EP(230909_180536): T_Loss: 0.531819 V_Loss: 0.509794 IoU: 0.482 Dice: 0.541\n",
      "Best Epoch: 32 Loss: 0.509794\n",
      "33EP(230909_180548): T_Loss: 0.531213 V_Loss: 0.499958 IoU: 0.486 Dice: 0.544\n",
      "Best Epoch: 33 Loss: 0.499958\n",
      "34EP(230909_180600): T_Loss: 0.525114 V_Loss: 0.505276 IoU: 0.483 Dice: 0.542\n",
      "35EP(230909_180611): T_Loss: 0.523801 V_Loss: 0.503331 IoU: 0.489 Dice: 0.547\n",
      "36EP(230909_180623): T_Loss: 0.520332 V_Loss: 0.502376 IoU: 0.486 Dice: 0.546\n",
      "37EP(230909_180634): T_Loss: 0.515352 V_Loss: 0.498348 IoU: 0.489 Dice: 0.548\n",
      "Best Epoch: 37 Loss: 0.498348\n",
      "38EP(230909_180646): T_Loss: 0.507068 V_Loss: 0.498393 IoU: 0.492 Dice: 0.552\n",
      "39EP(230909_180658): T_Loss: 0.505377 V_Loss: 0.501213 IoU: 0.494 Dice: 0.547\n",
      "40EP(230909_180709): T_Loss: 0.502143 V_Loss: 0.508356 IoU: 0.492 Dice: 0.548\n",
      "41EP(230909_180721): T_Loss: 0.50834 V_Loss: 0.496939 IoU: 0.491 Dice: 0.549\n",
      "Best Epoch: 41 Loss: 0.496939\n",
      "42EP(230909_180734): T_Loss: 0.509946 V_Loss: 0.42191 IoU: 0.592 Dice: 0.644\n",
      "Best Epoch: 42 Loss: 0.42191\n",
      "43EP(230909_180747): T_Loss: 0.500705 V_Loss: 0.506317 IoU: 0.496 Dice: 0.546\n",
      "44EP(230909_180758): T_Loss: 0.489953 V_Loss: 0.40895 IoU: 0.619 Dice: 0.66\n",
      "Best Epoch: 44 Loss: 0.40895\n",
      "45EP(230909_180811): T_Loss: 0.459096 V_Loss: 0.323568 IoU: 0.682 Dice: 0.757\n",
      "Best Epoch: 45 Loss: 0.323568\n",
      "46EP(230909_180823): T_Loss: 0.29468 V_Loss: 0.254365 IoU: 0.725 Dice: 0.824\n",
      "Best Epoch: 46 Loss: 0.254365\n",
      "47EP(230909_180834): T_Loss: 0.247702 V_Loss: 0.24299 IoU: 0.731 Dice: 0.826\n",
      "Best Epoch: 47 Loss: 0.24299\n",
      "48EP(230909_180846): T_Loss: 0.232562 V_Loss: 0.242293 IoU: 0.714 Dice: 0.818\n",
      "Best Epoch: 48 Loss: 0.242293\n",
      "49EP(230909_180858): T_Loss: 0.218658 V_Loss: 0.241505 IoU: 0.714 Dice: 0.818\n",
      "Best Epoch: 49 Loss: 0.241505\n",
      "50EP(230909_180909): T_Loss: 0.209601 V_Loss: 0.241292 IoU: 0.73 Dice: 0.83\n",
      "Best Epoch: 50 Loss: 0.241292\n",
      "Test Start Time: 230909_180910\n",
      "Best Epoch: 50\n",
      "Test(230909_180912): Loss: 0.241596 IoU: 0.743 Dice: 0.84\n",
      "00:09:50\n",
      "End 230909_180912\n",
      "OTSNet\n",
      "LR: 0.0001\n",
      "Training Start Time: 230909_180912\n",
      "1EP(230909_180924): T_Loss: 0.99984 V_Loss: 0.999914 IoU: 0.001 Dice: 0.0\n",
      "Best Epoch: 1 Loss: 0.999914\n",
      "2EP(230909_180936): T_Loss: 0.999781 V_Loss: 0.999796 IoU: 0.03 Dice: 0.0\n",
      "Best Epoch: 2 Loss: 0.999796\n",
      "3EP(230909_180948): T_Loss: 0.99972 V_Loss: 0.999645 IoU: 0.007 Dice: 0.001\n",
      "Best Epoch: 3 Loss: 0.999645\n",
      "4EP(230909_180959): T_Loss: 0.999628 V_Loss: 0.999559 IoU: 0.086 Dice: 0.001\n",
      "Best Epoch: 4 Loss: 0.999559\n",
      "5EP(230909_181011): T_Loss: 0.999483 V_Loss: 0.999426 IoU: 0.15 Dice: 0.001\n",
      "Best Epoch: 5 Loss: 0.999426\n",
      "6EP(230909_181022): T_Loss: 0.999234 V_Loss: 0.999003 IoU: 0.211 Dice: 0.002\n",
      "Best Epoch: 6 Loss: 0.999003\n",
      "7EP(230909_181035): T_Loss: 0.998761 V_Loss: 0.998555 IoU: 0.282 Dice: 0.003\n",
      "Best Epoch: 7 Loss: 0.998555\n",
      "8EP(230909_181047): T_Loss: 0.997845 V_Loss: 0.997431 IoU: 0.368 Dice: 0.005\n",
      "Best Epoch: 8 Loss: 0.997431\n",
      "9EP(230909_181059): T_Loss: 0.995395 V_Loss: 0.999071 IoU: 0.244 Dice: 0.002\n",
      "10EP(230909_181111): T_Loss: 0.979058 V_Loss: 0.999665 IoU: 0.073 Dice: 0.001\n",
      "11EP(230909_181123): T_Loss: 0.955169 V_Loss: 0.999734 IoU: 0.001 Dice: 0.0\n",
      "12EP(230909_181135): T_Loss: 0.930516 V_Loss: 0.99987 IoU: 0.0 Dice: 0.0\n",
      "13EP(230909_181147): T_Loss: 0.892812 V_Loss: 0.871831 IoU: 0.191 Dice: 0.161\n",
      "Best Epoch: 13 Loss: 0.871831\n",
      "14EP(230909_181158): T_Loss: 0.825251 V_Loss: 0.752619 IoU: 0.301 Dice: 0.298\n",
      "Best Epoch: 14 Loss: 0.752619\n",
      "15EP(230909_181210): T_Loss: 0.765493 V_Loss: 0.876592 IoU: 0.307 Dice: 0.169\n",
      "16EP(230909_181222): T_Loss: 0.66456 V_Loss: 0.631391 IoU: 0.392 Dice: 0.418\n",
      "Best Epoch: 16 Loss: 0.631391\n",
      "17EP(230909_181234): T_Loss: 0.619921 V_Loss: 0.61117 IoU: 0.395 Dice: 0.438\n",
      "Best Epoch: 17 Loss: 0.61117\n",
      "18EP(230909_181246): T_Loss: 0.604621 V_Loss: 0.591771 IoU: 0.394 Dice: 0.448\n",
      "Best Epoch: 18 Loss: 0.591771\n",
      "19EP(230909_181258): T_Loss: 0.595482 V_Loss: 0.59486 IoU: 0.388 Dice: 0.442\n",
      "20EP(230909_181309): T_Loss: 0.58944 V_Loss: 0.591861 IoU: 0.386 Dice: 0.443\n",
      "21EP(230909_181320): T_Loss: 0.581057 V_Loss: 0.588372 IoU: 0.39 Dice: 0.445\n",
      "Best Epoch: 21 Loss: 0.588372\n",
      "22EP(230909_181332): T_Loss: 0.580385 V_Loss: 0.590763 IoU: 0.392 Dice: 0.446\n",
      "23EP(230909_181344): T_Loss: 0.556149 V_Loss: 0.569734 IoU: 0.423 Dice: 0.473\n",
      "Best Epoch: 23 Loss: 0.569734\n",
      "24EP(230909_181356): T_Loss: 0.497367 V_Loss: 0.446152 IoU: 0.55 Dice: 0.613\n",
      "Best Epoch: 24 Loss: 0.446152\n",
      "25EP(230909_181407): T_Loss: 0.457513 V_Loss: 0.430646 IoU: 0.559 Dice: 0.631\n",
      "Best Epoch: 25 Loss: 0.430646\n",
      "26EP(230909_181419): T_Loss: 0.453295 V_Loss: 0.44576 IoU: 0.54 Dice: 0.61\n",
      "27EP(230909_181431): T_Loss: 0.459269 V_Loss: 0.471743 IoU: 0.516 Dice: 0.584\n",
      "28EP(230909_181443): T_Loss: 0.447105 V_Loss: 0.457076 IoU: 0.514 Dice: 0.591\n",
      "29EP(230909_181454): T_Loss: 0.433716 V_Loss: 0.456041 IoU: 0.511 Dice: 0.584\n",
      "30EP(230909_181506): T_Loss: 0.444907 V_Loss: 0.466947 IoU: 0.504 Dice: 0.578\n",
      "31EP(230909_181518): T_Loss: 0.41034 V_Loss: 0.416658 IoU: 0.544 Dice: 0.628\n",
      "Best Epoch: 31 Loss: 0.416658\n",
      "32EP(230909_181531): T_Loss: 0.401948 V_Loss: 0.410274 IoU: 0.561 Dice: 0.64\n",
      "Best Epoch: 32 Loss: 0.410274\n",
      "33EP(230909_181542): T_Loss: 0.398682 V_Loss: 0.413431 IoU: 0.551 Dice: 0.632\n",
      "34EP(230909_181555): T_Loss: 0.395253 V_Loss: 0.416177 IoU: 0.547 Dice: 0.631\n",
      "35EP(230909_181606): T_Loss: 0.393247 V_Loss: 0.414298 IoU: 0.565 Dice: 0.641\n",
      "36EP(230909_181618): T_Loss: 0.385527 V_Loss: 0.401374 IoU: 0.572 Dice: 0.653\n",
      "Best Epoch: 36 Loss: 0.401374\n",
      "37EP(230909_181630): T_Loss: 0.363345 V_Loss: 0.38551 IoU: 0.597 Dice: 0.672\n",
      "Best Epoch: 37 Loss: 0.38551\n",
      "38EP(230909_181642): T_Loss: 0.342751 V_Loss: 0.350555 IoU: 0.639 Dice: 0.72\n",
      "Best Epoch: 38 Loss: 0.350555\n",
      "39EP(230909_181655): T_Loss: 0.264869 V_Loss: 0.2881 IoU: 0.685 Dice: 0.788\n",
      "Best Epoch: 39 Loss: 0.2881\n",
      "40EP(230909_181706): T_Loss: 0.244637 V_Loss: 0.288065 IoU: 0.683 Dice: 0.785\n",
      "Best Epoch: 40 Loss: 0.288065\n",
      "41EP(230909_181719): T_Loss: 0.238635 V_Loss: 0.289863 IoU: 0.68 Dice: 0.783\n",
      "42EP(230909_181730): T_Loss: 0.23965 V_Loss: 0.276166 IoU: 0.688 Dice: 0.794\n",
      "Best Epoch: 42 Loss: 0.276166\n",
      "43EP(230909_181742): T_Loss: 0.233857 V_Loss: 0.271899 IoU: 0.686 Dice: 0.794\n",
      "Best Epoch: 43 Loss: 0.271899\n",
      "44EP(230909_181753): T_Loss: 0.226111 V_Loss: 0.273079 IoU: 0.685 Dice: 0.793\n",
      "45EP(230909_181804): T_Loss: 0.219987 V_Loss: 0.266011 IoU: 0.7 Dice: 0.805\n",
      "Best Epoch: 45 Loss: 0.266011\n",
      "46EP(230909_181815): T_Loss: 0.223075 V_Loss: 0.269244 IoU: 0.695 Dice: 0.801\n",
      "47EP(230909_181828): T_Loss: 0.218806 V_Loss: 0.26584 IoU: 0.693 Dice: 0.799\n",
      "Best Epoch: 47 Loss: 0.26584\n",
      "48EP(230909_181839): T_Loss: 0.210664 V_Loss: 0.267471 IoU: 0.679 Dice: 0.79\n",
      "49EP(230909_181851): T_Loss: 0.206665 V_Loss: 0.265383 IoU: 0.685 Dice: 0.793\n",
      "Best Epoch: 49 Loss: 0.265383\n",
      "50EP(230909_181902): T_Loss: 0.198382 V_Loss: 0.264919 IoU: 0.686 Dice: 0.797\n",
      "Best Epoch: 50 Loss: 0.264919\n",
      "Test Start Time: 230909_181902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch: 50\n",
      "Test(230909_181904): Loss: 0.257634 IoU: 0.708 Dice: 0.81\n",
      "00:09:52\n",
      "End 230909_181904\n"
     ]
    }
   ],
   "source": [
    "Dataset_Number=0\n",
    "for image_paths_dir, target_dir in zip(image_paths_dirs, target_dirs):\n",
    "    Dataset_name = os.path.basename(target_dir)\n",
    "    if Dataset_name not in Target_Datasets:\n",
    "        continue\n",
    "    Dataset_Number+=1\n",
    "    print(str(Dataset_Number)+'/'+str(len(Target_Datasets)), Dataset_name)\n",
    "    for iteration in range(iterations[0], iterations[1]+1):\n",
    "        seed=iteration    \n",
    "        for model_name in model_names:\n",
    "            if len(df[(df['Dataset'] ==Dataset_name) & (df['Model Name']== model_name) & (df['Iteration']== iteration)]) > 0:\n",
    "                continue\n",
    "            image_path_list=natsort.natsorted(glob.glob(image_paths_dir+'/*'))\n",
    "            target_path_list=[]\n",
    "            for image_path in image_path_list:\n",
    "                target_path_list.append(target_dir+'/'+os.path.basename(image_path).replace('npy','png'))\n",
    "            transform = transforms.Compose([\n",
    "                        transforms.ToPILImage(),\n",
    "#                         transforms.Resize((224,224)),\n",
    "                        transforms.ToTensor(),\n",
    "                ])\n",
    "            num_workers=4\n",
    "            shuffle=True\n",
    "            pin_memory=True\n",
    "            num_dataset = len(target_path_list)\n",
    "            indices = list(range(num_dataset))\n",
    "            split1=int(train_size*num_dataset)\n",
    "            split2=int((train_size+(1-train_size)/2)*num_dataset)\n",
    "            control_random_seed(seed)\n",
    "            if shuffle:\n",
    "                np.random.shuffle(indices)\n",
    "            train_idx, validation_idx, test_idx = indices[:split1], indices[split1:split2], indices[split2:]\n",
    "            train_image_path_list=[]\n",
    "            train_target_path_list=[]\n",
    "            validation_image_path_list=[]\n",
    "            validation_target_path_list=[]\n",
    "            test_image_path_list=[]\n",
    "            test_target_path_list=[]\n",
    "            for i, index in enumerate(indices):\n",
    "                if i<split1:\n",
    "                    train_image_path_list.append(image_path_list[index])\n",
    "                    train_target_path_list.append(target_path_list[index])\n",
    "                elif split1<=i and i<split2:\n",
    "                    validation_image_path_list.append(image_path_list[index])\n",
    "                    validation_target_path_list.append(target_path_list[index])\n",
    "                else:\n",
    "                    test_image_path_list.append(image_path_list[index])\n",
    "                    test_target_path_list.append(target_path_list[index])\n",
    "\n",
    "            print(model_name)\n",
    "            for Optimizer in Optimizers :\n",
    "                for lr in LRs:\n",
    "                    print('LR:',lr)\n",
    "                    control_random_seed(seed)\n",
    "                    in_channels=3\n",
    "                    model=str_to_class(model_name)(in_channels, number_of_classes)\n",
    "                    device = torch.device(\"cuda:\"+str(devices[0]))\n",
    "                    if len(devices)>1:\n",
    "                        model = torch.nn.DataParallel(model, device_ids = devices ).to(device)\n",
    "                    else:\n",
    "                        model = model.to(device)\n",
    "                    df = Do_Experiment(iteration, model_name, model, Optimizer, lr,  number_of_classes, epochs, Metrics,df,device)\n",
    "                    try:\n",
    "                        df.to_csv('Segmentation_Model_Comparison_Performance_'+Experiment_date+'.csv', index=False, header=True, encoding=\"cp949\")\n",
    "                    except:\n",
    "                        now = datetime.now()\n",
    "                        tmp_date=now.strftime(\"%y%m%d_%H%M%S\")\n",
    "                        df.to_csv('Segmentation_Model_Comparison_Performance_'+Experiment_date+'_'+tmp_date+'_tmp'+'.csv', index=False, header=True, encoding=\"cp949\")\n",
    "# import os\n",
    "# print('End')\n",
    "# os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f47470-84ef-40bb-8613-0b149d20ebe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ots",
   "language": "python",
   "name": "ots"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
